#!/usr/bin/env python
import sys
import os

# make fluxy files accessible
directory = os.path.join(os.path.dirname(__file__), '..')
sys.path.append(os.path.abspath(directory))

from django.core import management
from fluxy import settings as fluxy_settings
from datetime import datetime
from boto.s3 import connection as s3
from boto import utils
import time
import subprocess


def main():
  # set up django environment
  management.setup_environ(fluxy_settings)
  from django.conf import settings

  # backups happen every 30 minutes; take the backup from the previous hour
  an_hour_ago = datetime.fromtimestamp(time.time() - 60 * 60)
  stamp = an_hour_ago.strftime('%m-%d-%Y-%H:30')

  connection = s3.S3Connection(settings.AWS_S3_ACCESS_KEY_ID,
    settings.AWS_S3_SECRET_ACCESS_KEY)
  bucket = connection.get_bucket(settings.AWS_PRODUCTION_BACKUPS_BUCKET_NAME)

  keys = bucket.list()
  key = max(keys, key=get_last_modified_time)

  # Fetch backup from S3. Macs can't handle ':' in file names, so we replace them.
  temp_file_name = '/tmp/backup-%s.dump' % stamp.replace(':', '-')
  print 'Fetching file %s to %s' % (key.name, temp_file_name)
  key.get_contents_to_filename(temp_file_name)

  # restore backup
  print 'Restoring backup...'
  print subprocess.check_output(['psql', '-f', temp_file_name, 'postgres'])


def get_last_modified_time(key):
  """
  Returns the last modified time of the given S3 key. The time is in seconds
  from the epoch.
  """
  parsed_datetime = utils.parse_ts(key.last_modified)
  return time.mktime(parsed_datetime.timetuple())


if __name__ == '__main__':
  main()
